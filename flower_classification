
# Imports here
%matplotlib inline

import matplotlib.pyplot as plt
import numpy as np
import sys
import os, random
import time, json
from PIL import Image
import torch
from torch import nn
from torch import optim
#from torch import Tensor
#import torch.nn.functional as F
from torch.autograd import Variable
import torchvision
from torchvision import datasets, models, transforms
import torchvision.models as models
from collections import OrderedDict


from workspace_utils import active_session

data_dir = 'flowers'
train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
test_dir = data_dir + '/test'

# TODO: Define your transforms for the training, validation, and testing sets
data_transforms = {
    'train' :  transforms.Compose([transforms.RandomResizedCrop(224),#, scale=(0.8, 1.0)),
                                       transforms.RandomRotation(45),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.ToTensor(),
                                       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),

'validation': transforms.Compose([transforms.Resize(256),
                                       transforms.CenterCrop(224),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),

'test': transforms.Compose([transforms.Resize(256),
                                       transforms.CenterCrop(224),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])     
}                                       

# TODO: Load the datasets with ImageFolder
image_datasets = {
'train_data': datasets.ImageFolder(train_dir, transform=data_transforms['train']),
'valid_data': datasets.ImageFolder(valid_dir, transform=data_transforms['validation']),
'test_data': datasets.ImageFolder(test_dir, transform=data_transforms['test'])}

# TODO: Using the image datasets and the trainforms, define the dataloaders
data_loader = {
'train_loader': torch.utils.data.DataLoader(image_datasets['train_data'], batch_size=32, shuffle=True),
'valid_loader': torch.utils.data.DataLoader(image_datasets['valid_data'], batch_size=32,shuffle=True),
'test_loader': torch.utils.data.DataLoader(image_datasets['test_data'], batch_size=32, shuffle=True)}    
    


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

import json

with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)
    
model = models.vgg16_bn(pretrained=True)
model

model.classifier

for param in model.parameters():
    param.requires_grad = False

classifier = nn.Sequential(OrderedDict([
    ('fc1', nn.Linear(25088,4096)),
    ('relu', nn.ReLU()),
    ('dropout', nn.Dropout(0.5)),
    ('fc2', nn.Linear(4096, len(cat_to_name))),
    ('output', nn.LogSoftmax(dim=1))
]))

model.classifier = classifier

model.classifier

criterion = nn.NLLLoss()
optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)

# TODO: Build and train your network
def model_train_validate(model_param, criterion_param, optimizer_param, data_loader_param, epochs=3, print_every=40):


    with active_session():
        model_param.to(device)
        for e in range(epochs):
            train_count = 0
            valid_count = 0

            train_loss = 0
            valid_loss = 0
            train_accuracy = 0 
            valid_accuracy = 0

            total = 0
            correct = 0

            for ii, (inputs, labels) in enumerate(data_loader_param['train_loader']):
                train_count += 1

                model_param.train()
                inputs, labels = inputs.to(device), labels.to(device)

                optimizer_param.zero_grad()

                # Forward and backward passes
                outputs = model_param.forward(inputs)
                loss = criterion_param(outputs, labels)
                loss.backward()
                optimizer_param.step()

                train_loss += loss.item()

                if train_count % print_every == 0:
                    print("Train count: {}".format(train_count))
                    print("Epoch: {}/{}... ".format(e+1, epochs),
                                     "Training Loss: {:.4f}".format(train_loss/print_every))
                    train_loss = 0

            for ii, (inputs, labels) in enumerate(data_loader_param['valid_loader']):
                valid_count += 1
                model_param.eval()
                inputs, labels = inputs.to(device),labels.to(device)

                optimizer_param.zero_grad()

                outputs = model_param.forward(inputs)
                loss = criterion_param(outputs, labels)

                valid_loss += loss.item()

                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

                #if valid_count % print_every == 0:
                print("Valid count: {}".format(valid_count))
                print("Valid Loss: {:.4f}".format(valid_loss/len(data_loader_param['valid_loader'])))
                valid_loss = 0 
            print('\nValidation accuracy: {:.3f}'.format(correct/total*100))
    return model_param
        
model = model_train_validate(model, criterion, optimizer, data_loader)    


# Test network
def test_accuracy(model_param, data_loader_param):    
    correct = 0
    total = 0
    model_param.eval()
    with torch.no_grad():
        for ii, (inputs, labels) in enumerate(data_loader['test_loader']):
            inputs, labels = inputs.to(device), labels.to(device)
            output = model_param(inputs)
            _, predicted = torch.max(output.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print('Accuracy of the network: %d %%' % (100 * correct / total))
test_accuracy(model, data_loader)


#plt.figure()
plt.plot(train_loss, label='Training loss')
plt.plot(valid_loss, label='Validation loss')
plt.legend()
#plt.show()

#Save the checkpoint
#Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: image_datasets['train'].class_to_idx. You can attach this to the model as an attribute which makes inference easier later on.
#model.class_to_idx = image_datasets['train'].class_to_idx
#Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, optimizer.state_dict. You'll likely want to use this trained model in the next part of the project, so best to save it now.

dest_dir = None

# TODO: Save the checkpoint 
def save_checkpoint(model_param, optimizer_param, filename_param, train_data_param, dest_dir_param=None):
    
    model_param.class_to_idx = train_data_param.class_to_idx

    checkpoint = {'classifier': model_param.classifier,
                   'state_dict': model_param.state_dict(), 
                   'optimizer': optimizer_param,
                   'optimizer_state_dict': optimizer_param.state_dict(),
                   'class_to_idx': model_param.class_to_idx} 
    checkpoint_path = dest_dir_param + filename_param
    torch.save(checkpoint, checkpoint_path)

# TODO: Write a function that loads a checkpoint and rebuilds the model

def load_checkpoint(checkpoint_path):
    checkpoint = torch.load(checkpoint_path)
    model = models.vgg16_bn(pretrained=True)
    
    for param in model.parameters():
        param.requires_grad = False
    
    model.class_to_dix = checkpoint['class_to_idx']
    
    model.classifier = checkpoint['classifier']
    
    model.load_state_dict(checkpoint['state_dict'])
    optimizer = checkpoint['optimizer']
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    return model, optimizer
    
model, optimizer = load_checkpoint('vgg16_bn_flower_classification.pth')    

any_img_path = test_dir + '/34/image_06961.jpg'
img = Image.open(any_img_path)

img

def process_image(image):
    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,
        returns an Numpy array
    '''
    
    # TODO: Process a PIL image for use in a PyTorch model
    
    transform = transforms.Compose([transforms.Resize(256),
                                   transforms.CenterCrop(224),
                                   transforms.ToTensor(),
                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
    
    load_img = Image.open(image)
                         
    pil_img = transform(load_img).float()
    pil_img = pil_img.unsqueeze(0)                     
    return np.array(pil_img)


#To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your process_image function works, running the output through this function should return the original image (except for the cropped out portions).


def imshow(image, ax=None, title=None):
    """Imshow for Tensor."""
    if ax is None:
        fig, ax = plt.subplots()
    
    # PyTorch tensors assume the color channel is the first dimension
    # but matplotlib assumes is the third dimension
    image = image.numpy().transpose((1, 2, 0))
    
    # Undo preprocessing
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image = std * image + mean
    
    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed
    image = np.clip(image, 0, 1)
    
    ax.imshow(image)
    
    return ax
    
img = random.choice(os.listdir('./flowers/test/7/'))
img_path = './flowers/test/7/' + img

with Image.open(img_path) as image:
    plt.imshow(image)
    
#Class Prediction
#Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top- 𝐾
#K
# ) most probable classes. You'll want to calculate the class probabilities then find the  𝐾
#K
#  largest values.
#To get the top  𝐾
#K
#  largest values in a tensor use x.topk(k). This method returns both the highest k probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using class_to_idx which hopefully you added to the model or from an ImageFolder you used to load the data (see here). Make sure to invert the dictionary so you get a mapping from index to class as well.
#Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.
#probs, classes = predict(image_path, model)
#print(probs)
#print(classes)
#> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]
#> ['70', '3', '45', '62', '55']
#In [ ]:

def predict(image_path_param, model_param, k_param=5):
    ''' Predict the class (or classes) of an image using a trained deep learning model.
    '''
    
    # TODO: Implement the code to predict the class from an image file
    model_param.eval()
    pil_img = process_image(image_path_param)
    pil_img = torch.from_numpy(pil_img)
   
    pil_img = pil_img.cuda()
    model_param = model_param.cuda()
        
    output = model_param(pil_img)
    
    output = nn.Softmax()(output)

    probs = torch.topk(output,k_param)[0]
    labels = torch.topk(output,k_param)[1]
    
   
    probs = probs.cpu()
    labels = labels.cpu()
        
    print(pil_img)    
    return pil_img, probs.detach().numpy(), labels.detach().numpy()    

# TODO: Display an image along with the top 5 classes
def display_pred_img(image_path_param, model_param, k_param=5):
    image, probabilities, predictions = predict(image_path_param, model_param, k_param)
    
    idx_to_name = {category: cat_to_name[str(category)] for category in predictions[0]}
    
    class_names = list(idx_to_name.values())
    
    image = image.cpu().squeeze()
        
    df = pd.DataFrame({'probability': probabilities[0]}, index = class_names) 
    
    # plot image
    plt.figure(figsize =(16,5))
    ax = plt.subplot(1,2,1)
    ax = imshow(image, ax=ax)
    
    ax.set_title(class_names[0], size=20)
    
    ax = plt.subplot(1,2,2)
    
    df.sort_values('probability')['probability'].plot.barh(color='green', ax=ax)
    
    plt.xlabel('Predicted Probability')
    
    
img_path_test = './flowers/test/74/image_01173.jpg'

display_pred_img(img_path_test, model)
